{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Torchvision DenseNet","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qfCJ9vUM2rKf","colab_type":"code","colab":{}},"source":["# Load the Drive helper and mount \n","from google.colab import drive\n","# # This will prompt for authorization.\n","drive.mount('/content/drive/')\n","# #Navigate to the directory containing this notebook\n","%cd \"/content/drive/My Drive/StarliperSongkakul-Project3/Dense2Net\"\n","\n","\n","!ls"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHc4AqEg2ftF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":4522},"outputId":"9e2b3507-25de-4b18-bc60-8dabb53d6d8c","executionInfo":{"status":"error","timestamp":1556930817724,"user_tz":240,"elapsed":337584,"user":{"displayName":"Tanner Songkakul","photoUrl":"","userId":"16302517323990624028"}}},"source":["import re\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","#from .utils import load_state_dict_from_url\n","from collections import OrderedDict\n","\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import os\n","import time\n","import sys\n","import numpy as np\n","import pickle as pkl\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n","\n","__all__ = ['DenseNet', 'densenet121', 'densenet169', 'densenet201', 'densenet161']\n","\n","model_urls = {\n","    'densenet121': 'https://download.pytorch.org/models/densenet121-a639ec97.pth',\n","    'densenet169': 'https://download.pytorch.org/models/densenet169-b2777c0a.pth',\n","    'densenet201': 'https://download.pytorch.org/models/densenet201-c1103571.pth',\n","    'densenet161': 'https://download.pytorch.org/models/densenet161-8d451a50.pth',\n","}\n","\n","\n","class _DenseLayer(nn.Sequential):\n","    def __init__(self, num_input_features, growth_rate, bn_size, drop_rate):\n","        super(_DenseLayer, self).__init__()\n","        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n","        self.add_module('relu1', nn.ReLU(inplace=True)),\n","        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n","                                           growth_rate, kernel_size=1, stride=1,\n","                                           bias=False)),\n","        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n","        self.add_module('relu2', nn.ReLU(inplace=True)),\n","        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n","                                           kernel_size=3, stride=1, padding=1,\n","                                           bias=False)),\n","        self.drop_rate = drop_rate\n","\n","    def forward(self, x):\n","        new_features = super(_DenseLayer, self).forward(x)\n","        if self.drop_rate > 0:\n","            new_features = F.dropout(new_features, p=self.drop_rate,\n","                                     training=self.training)\n","        return torch.cat([x, new_features], 1)\n","\n","\n","class _DenseBlock(nn.Sequential):\n","    def __init__(self, num_layers, num_input_features, bn_size, growth_rate, drop_rate):\n","        super(_DenseBlock, self).__init__()\n","        for i in range(num_layers):\n","            layer = _DenseLayer(num_input_features + i * growth_rate, growth_rate,\n","                                bn_size, drop_rate)\n","            self.add_module('denselayer%d' % (i + 1), layer)\n","\n","\n","class _Transition(nn.Sequential):\n","    def __init__(self, num_input_features, num_output_features):\n","        super(_Transition, self).__init__()\n","        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n","        self.add_module('relu', nn.ReLU(inplace=True))\n","        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n","                                          kernel_size=1, stride=1, bias=False))\n","        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n","\n","\n","class DenseNet(nn.Module):\n","    r\"\"\"Densenet-BC model class, based on\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        growth_rate (int) - how many filters to add each layer (`k` in paper)\n","        block_config (list of 4 ints) - how many layers in each pooling block\n","        num_init_features (int) - the number of filters to learn in the first convolution layer\n","        bn_size (int) - multiplicative factor for number of bottle neck layers\n","          (i.e. bn_size * k features in the bottleneck layer)\n","        drop_rate (float) - dropout rate after each dense layer\n","        num_classes (int) - number of classification classes\n","    \"\"\"\n","\n","    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n","                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=100): #TANNER: changed drop rate to 0.2 from 0\n","\n","        super(DenseNet, self).__init__()\n","\n","        # First convolution\n","        self.features = nn.Sequential(OrderedDict([\n","            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=7, stride=2,\n","                                padding=3, bias=False)),\n","            ('norm0', nn.BatchNorm2d(num_init_features)),\n","            ('relu0', nn.ReLU(inplace=True)),\n","            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=1)),\n","        ]))\n","\n","        # Each denseblock\n","        num_features = num_init_features\n","        for i, num_layers in enumerate(block_config):\n","            block = _DenseBlock(num_layers=num_layers, num_input_features=num_features,\n","                                bn_size=bn_size, growth_rate=growth_rate,\n","                                drop_rate=drop_rate)\n","            self.features.add_module('denseblock%d' % (i + 1), block)\n","            num_features = num_features + num_layers * growth_rate\n","            if i != len(block_config) - 1:\n","                trans = _Transition(num_input_features=num_features,\n","                                    num_output_features=num_features // 2)\n","                self.features.add_module('transition%d' % (i + 1), trans)\n","                num_features = num_features // 2\n","\n","        # Final batch norm\n","        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n","\n","        # Linear layer\n","        self.classifier = nn.Linear(num_features, num_classes)\n","\n","        # Official init from torch repo.\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight)\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        features = self.features(x)\n","        out = F.relu(features, inplace=True)\n","        out = F.adaptive_avg_pool2d(out, (1, 1)).view(features.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","\n","def _load_state_dict(model, model_url, progress):\n","    # '.'s are no longer allowed in module names, but previous _DenseLayer\n","    # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n","    # They are also in the checkpoints in model_urls. This pattern is used\n","    # to find such keys.\n","    pattern = re.compile(\n","        r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n","\n","    state_dict = load_state_dict_from_url(model_url, progress=progress)\n","    for key in list(state_dict.keys()):\n","        res = pattern.match(key)\n","        if res:\n","            new_key = res.group(1) + res.group(2)\n","            state_dict[new_key] = state_dict[key]\n","            del state_dict[key]\n","    model.load_state_dict(state_dict)\n","\n","\n","def _densenet(arch, growth_rate, block_config, num_init_features, pretrained, progress,\n","              **kwargs):\n","    model = DenseNet(growth_rate, block_config, num_init_features, **kwargs)\n","    if pretrained:\n","        _load_state_dict(model, model_urls[arch], progress)\n","    return model\n","\n","\n","def densenet121(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-121 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress,\n","                     **kwargs) #TANNER: changed growth rate to 12 from 32\n","\n","\n","def densenet161(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-161 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _densenet('densenet161', 48, (6, 12, 36, 24), 96, pretrained, progress,\n","                     **kwargs)\n","\n","\n","def densenet169(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-169 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _densenet('densenet169', 32, (6, 12, 32, 32), 64, pretrained, progress,\n","                     **kwargs)\n","\n","\n","def densenet201(pretrained=False, progress=True, **kwargs):\n","    r\"\"\"Densenet-201 model from\n","    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _densenet('densenet201', 32, (6, 12, 48, 32), 64, pretrained, progress,\n","                     **kwargs)\n","      \n","def conv3x3(in_planes, out_planes, stride=1, groups=1):  \n","    #returns a 3x3 2d convolution, used in Res2Net sub-convolutions\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=1, groups=groups, bias=False)\n","\n","class Res2Net_block(nn.Module):\n","    #Res2net bottleneck block\n","    def __init__(self, planes, scale=1, stride=1, groups=1, norm_layer=None):\n","        super(Res2Net_block, self).__init__()\n","        \n","        self.relu = nn.ReLU(inplace=True)\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","            \n","        self.scale = scale\n","        ch_per_sub = planes // self.scale\n","        ch_res = planes % self.scale    \n","        self.chunks  = [ch_per_sub * i + ch_res for i in range(1, scale + 1)]\n","        self.conv_blocks = self.get_sub_convs(ch_per_sub, norm_layer, stride, groups)\n","        \n","    def forward(self, x):\n","        sub_convs = []\n","        sub_convs.append(x[:, :self.chunks[0]])\n","        sub_convs.append(self.conv_blocks[0](x[:, self.chunks[0]: self.chunks[1]]))\n","        for s in range(2, self.scale):\n","            sub_x = x[:, self.chunks[s-1]: self.chunks[s]]\n","            sub_x += sub_convs[-1]\n","            sub_convs.append(self.conv_blocks[s-1](sub_x))\n","\n","        return torch.cat(sub_convs, dim=1)\n","    \n","    def get_sub_convs(self, ch_per_sub, norm_layer, stride, groups):\n","        layers = []\n","        for _ in range(1, self.scale):\n","            layers.append(nn.Sequential(\n","                conv3x3(ch_per_sub, ch_per_sub, stride, groups),\n","                norm_layer(ch_per_sub), self.relu))\n","        \n","        return nn.Sequential(*layers)\n","\n","      \n","# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    overfit = 0\n","    overfit_limit = 99.98\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    avg_loss = 0\n","    acc = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","        acc = 100. * correct / total\n","        avg_loss = train_loss/(batch_idx+1)\n","        if(batch_idx%25==0) or batch_idx==len(trainloader)-1:\n","          print(batch_idx+1, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (avg_loss, acc, correct, total))\n","    \n","    if acc>overfit_limit:\n","        overfit=1\n","        \n","    return avg_loss, acc, overfit\n","\n","\n","def test(epoch):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    avg_loss = 0\n","    acc = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","            acc = 100. * correct / total\n","            avg_loss = test_loss / (batch_idx + 1)\n","            if(batch_idx%25==0) or batch_idx==len(testloader)-1:\n","                print(batch_idx+1, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","\n","    # Save checkpoint.\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': net.state_dict(),\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir('checkpoint'):\n","            os.mkdir('checkpoint')\n","        torch.save(state, './checkpoint/ckpt.t7')\n","        best_acc = acc\n","    return avg_loss, acc\n","\n","\n","def plot_curves(train, test, mode):\n","    if mode == 1:\n","        title = \"Accuracy Curves\"\n","        label = \"Accuracy\"\n","        filename = \"acc.png\"\n","    else:\n","        title = \"Loss Curves\"\n","        label = \"Loss\"\n","        filename = \"loss.png\"\n","    num_epochs_plot = range(0, len(train))  # x axis range\n","    plt.figure()\n","    plt.plot(num_epochs_plot, train, \"b\", label=\"Training\")\n","    plt.plot(num_epochs_plot, test, \"r\", label=\"Validation\")\n","    plt.title(title)\n","    plt.xlabel(\"Number of Epochs\")\n","    plt.ylabel(label)\n","    plt.legend()\n","    plt.savefig(filename)\n","    plt.close()\n","\n","if __name__ == '__main__':\n","\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    best_acc = 0  # best test accuracy\n","    start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n","    end_epoch = 100 # number of epochs to run\n","    augment = 1 # set to 1 to augment data\n","    resume = 0 # resume from checkpoint \n","\n","    # Data\n","    print('==> Preparing data..')\n","    if augment==0: #TANNER: this was backwards before, switched in v2\n","      transform_train = transforms.Compose([\n","          transforms.ToTensor(),\n","          #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #CIFAR10\n","          transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]), #CIFAR100\n","\n","      ])\n","    else:\n","      transform_train = transforms.Compose([\n","          transforms.RandomCrop(32, padding=4),\n","          transforms.RandomHorizontalFlip(),\n","          transforms.ToTensor(),\n","          #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #CIFAR10\n","          transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]), #CIFAR100\n","      ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        #transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), #CIFAR10\n","        transforms.Normalize(mean=[0.507, 0.487, 0.441], std=[0.267, 0.256, 0.276]), #CIFAR100\n","    ])\n","\n","    trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n","    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","    testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","    # classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","    # Model\n","    print('==> Building model..')\n","    net = densenet121(False)\n","    net = net.to(device)\n","    if device == 'cuda':\n","        net = nn.DataParallel(net)\n","        cudnn.benchmark = True\n","    \n","    learning_rate = 0.1\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001) #(tanner): changed weight decay to 0.0001 to match Res2net paper\n","\n","\n","    train_loss = np.zeros((end_epoch, 1))\n","    train_acc = np.zeros((end_epoch, 1))\n","    test_acc = np.zeros((end_epoch, 1))\n","    test_loss = np.zeros((end_epoch, 1))\n","\n","    if resume == 1:\n","\t    # Load checkpoint.\n","\t    print('==> Resuming from checkpoint..')\n","\t    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","\t    checkpoint = torch.load('./checkpoint/ckpt.t7')\n","\t    net.load_state_dict(checkpoint['net'])\n","\t    best_acc = checkpoint['acc']\n","\t    start_epoch = checkpoint['epoch']\n","\t    with open('results.pkl', 'rb') as file:\n","      \t\ttrain_loss, train_acc, test_loss, test_acc = pkl.load(file)\n","\n","    track_overfit = 0\n","    #train and test\n","    start_time = time.time()\n","    last_epoch = end_epoch\n","    for epoch in range(start_epoch, end_epoch):\n","      if (epoch == 50) or (epoch == 75):#((epoch+1)%30)==0:\n","          for g in optimizer.param_groups:\n","            learning_rate /= 10\n","            g['lr'] = learning_rate #reduce learning rate by a factor of 10 every 30 epochs\n","            print('learning rate reduced to '+str(learning_rate))\n","\n","      train_loss[epoch], train_acc[epoch],overfit_check = train(epoch)\n","      test_loss[epoch], test_acc[epoch] = test(epoch)\n","      results = [train_loss, train_acc, test_loss, test_acc]\n","      with open('results.pkl', 'wb') as file:\n","          pkl.dump(results, file)\n","      track_overfit+= overfit_check\n","      if track_overfit>3:\n","          print('overfit, terminating run')\n","          last_epoch=epoch\n","          break\n","    #plot training and testing curves\n","    plot_curves(train_loss[0:last_epoch+1], test_loss[0:last_epoch+1], 0)\n","    plot_curves(train_acc[0:last_epoch+1], test_acc[0:last_epoch+1], 1)\n","    end_time = time.time()\n","    print('Total Time: ', (end_time - start_time))\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","==> Building model..\n","\n","Epoch: 0\n","1 391 Loss: 4.712 | Acc: 0.781% (1/128)\n","26 391 Loss: 4.966 | Acc: 3.185% (106/3328)\n","51 391 Loss: 4.913 | Acc: 3.554% (232/6528)\n","76 391 Loss: 4.827 | Acc: 4.019% (391/9728)\n","101 391 Loss: 4.732 | Acc: 4.494% (581/12928)\n","126 391 Loss: 4.623 | Acc: 5.066% (817/16128)\n","151 391 Loss: 4.536 | Acc: 5.443% (1052/19328)\n","176 391 Loss: 4.463 | Acc: 5.842% (1316/22528)\n","201 391 Loss: 4.402 | Acc: 6.281% (1616/25728)\n","226 391 Loss: 4.347 | Acc: 6.568% (1900/28928)\n","251 391 Loss: 4.294 | Acc: 6.975% (2241/32128)\n","276 391 Loss: 4.246 | Acc: 7.391% (2611/35328)\n","301 391 Loss: 4.199 | Acc: 7.841% (3021/38528)\n","326 391 Loss: 4.159 | Acc: 8.244% (3440/41728)\n","351 391 Loss: 4.122 | Acc: 8.551% (3842/44928)\n","376 391 Loss: 4.087 | Acc: 8.897% (4282/48128)\n","391 391 Loss: 4.064 | Acc: 9.196% (4598/50000)\n","1 100 Loss: 3.908 | Acc: 9.000% (9/100)\n","26 100 Loss: 3.840 | Acc: 15.769% (410/2600)\n","51 100 Loss: 3.878 | Acc: 15.549% (793/5100)\n","76 100 Loss: 3.947 | Acc: 15.342% (1166/7600)\n","100 100 Loss: 3.937 | Acc: 15.550% (1555/10000)\n","Saving..\n","\n","Epoch: 1\n","1 391 Loss: 3.704 | Acc: 14.062% (18/128)\n","26 391 Loss: 3.543 | Acc: 15.535% (517/3328)\n","51 391 Loss: 3.531 | Acc: 15.625% (1020/6528)\n","76 391 Loss: 3.493 | Acc: 16.098% (1566/9728)\n","101 391 Loss: 3.478 | Acc: 16.182% (2092/12928)\n","126 391 Loss: 3.472 | Acc: 16.183% (2610/16128)\n","151 391 Loss: 3.457 | Acc: 16.370% (3164/19328)\n","176 391 Loss: 3.447 | Acc: 16.593% (3738/22528)\n","201 391 Loss: 3.433 | Acc: 16.985% (4370/25728)\n","226 391 Loss: 3.422 | Acc: 17.257% (4992/28928)\n","251 391 Loss: 3.414 | Acc: 17.424% (5598/32128)\n","276 391 Loss: 3.401 | Acc: 17.575% (6209/35328)\n","301 391 Loss: 3.390 | Acc: 17.735% (6833/38528)\n","326 391 Loss: 3.377 | Acc: 18.007% (7514/41728)\n","351 391 Loss: 3.363 | Acc: 18.271% (8209/44928)\n","376 391 Loss: 3.350 | Acc: 18.526% (8916/48128)\n","391 391 Loss: 3.341 | Acc: 18.690% (9345/50000)\n","1 100 Loss: 3.072 | Acc: 24.000% (24/100)\n","26 100 Loss: 3.060 | Acc: 23.692% (616/2600)\n","51 100 Loss: 3.064 | Acc: 23.373% (1192/5100)\n","76 100 Loss: 3.077 | Acc: 23.434% (1781/7600)\n","100 100 Loss: 3.087 | Acc: 23.390% (2339/10000)\n","Saving..\n","\n","Epoch: 2\n","1 391 Loss: 3.074 | Acc: 25.781% (33/128)\n","26 391 Loss: 3.158 | Acc: 21.965% (731/3328)\n","51 391 Loss: 3.134 | Acc: 22.426% (1464/6528)\n","76 391 Loss: 3.118 | Acc: 22.852% (2223/9728)\n","101 391 Loss: 3.085 | Acc: 23.414% (3027/12928)\n","126 391 Loss: 3.090 | Acc: 23.227% (3746/16128)\n","151 391 Loss: 3.086 | Acc: 23.303% (4504/19328)\n","176 391 Loss: 3.087 | Acc: 23.295% (5248/22528)\n","201 391 Loss: 3.090 | Acc: 23.298% (5994/25728)\n","226 391 Loss: 3.107 | Acc: 23.092% (6680/28928)\n","251 391 Loss: 3.106 | Acc: 23.055% (7407/32128)\n","276 391 Loss: 3.096 | Acc: 23.287% (8227/35328)\n","301 391 Loss: 3.089 | Acc: 23.380% (9008/38528)\n","326 391 Loss: 3.081 | Acc: 23.543% (9824/41728)\n","351 391 Loss: 3.074 | Acc: 23.604% (10605/44928)\n","376 391 Loss: 3.074 | Acc: 23.591% (11354/48128)\n","391 391 Loss: 3.070 | Acc: 23.632% (11816/50000)\n","1 100 Loss: 3.029 | Acc: 26.000% (26/100)\n","26 100 Loss: 2.981 | Acc: 24.846% (646/2600)\n","51 100 Loss: 2.979 | Acc: 24.843% (1267/5100)\n","76 100 Loss: 2.982 | Acc: 24.882% (1891/7600)\n","100 100 Loss: 2.985 | Acc: 25.120% (2512/10000)\n","Saving..\n","\n","Epoch: 3\n","1 391 Loss: 2.840 | Acc: 24.219% (31/128)\n","26 391 Loss: 2.863 | Acc: 27.344% (910/3328)\n","51 391 Loss: 2.867 | Acc: 27.298% (1782/6528)\n","76 391 Loss: 2.872 | Acc: 27.076% (2634/9728)\n","101 391 Loss: 2.850 | Acc: 27.421% (3545/12928)\n","126 391 Loss: 2.844 | Acc: 27.400% (4419/16128)\n","151 391 Loss: 2.839 | Acc: 27.551% (5325/19328)\n","176 391 Loss: 2.831 | Acc: 27.752% (6252/22528)\n","201 391 Loss: 2.823 | Acc: 27.958% (7193/25728)\n","226 391 Loss: 2.816 | Acc: 28.149% (8143/28928)\n","251 391 Loss: 2.810 | Acc: 28.253% (9077/32128)\n","276 391 Loss: 2.803 | Acc: 28.408% (10036/35328)\n","301 391 Loss: 2.800 | Acc: 28.525% (10990/38528)\n","326 391 Loss: 2.798 | Acc: 28.571% (11922/41728)\n","351 391 Loss: 2.790 | Acc: 28.715% (12901/44928)\n","376 391 Loss: 2.784 | Acc: 28.804% (13863/48128)\n","391 391 Loss: 2.780 | Acc: 28.904% (14452/50000)\n","1 100 Loss: 2.692 | Acc: 39.000% (39/100)\n","26 100 Loss: 2.753 | Acc: 30.385% (790/2600)\n","51 100 Loss: 2.732 | Acc: 30.902% (1576/5100)\n","76 100 Loss: 2.727 | Acc: 30.711% (2334/7600)\n","100 100 Loss: 2.748 | Acc: 30.580% (3058/10000)\n","Saving..\n","\n","Epoch: 4\n","1 391 Loss: 2.737 | Acc: 24.219% (31/128)\n","26 391 Loss: 2.625 | Acc: 31.070% (1034/3328)\n","51 391 Loss: 2.620 | Acc: 31.893% (2082/6528)\n","76 391 Loss: 2.622 | Acc: 31.723% (3086/9728)\n","101 391 Loss: 2.637 | Acc: 31.351% (4053/12928)\n","126 391 Loss: 2.641 | Acc: 31.287% (5046/16128)\n","151 391 Loss: 2.650 | Acc: 31.203% (6031/19328)\n","176 391 Loss: 2.660 | Acc: 30.926% (6967/22528)\n","201 391 Loss: 2.663 | Acc: 30.819% (7929/25728)\n","226 391 Loss: 2.654 | Acc: 31.036% (8978/28928)\n","251 391 Loss: 2.649 | Acc: 31.225% (10032/32128)\n","276 391 Loss: 2.638 | Acc: 31.451% (11111/35328)\n","301 391 Loss: 2.628 | Acc: 31.655% (12196/38528)\n","326 391 Loss: 2.624 | Acc: 31.897% (13310/41728)\n","351 391 Loss: 2.618 | Acc: 32.018% (14385/44928)\n","376 391 Loss: 2.615 | Acc: 32.150% (15473/48128)\n","391 391 Loss: 2.611 | Acc: 32.212% (16106/50000)\n","1 100 Loss: 2.666 | Acc: 34.000% (34/100)\n","26 100 Loss: 2.576 | Acc: 35.269% (917/2600)\n","51 100 Loss: 2.578 | Acc: 34.549% (1762/5100)\n","76 100 Loss: 2.588 | Acc: 34.039% (2587/7600)\n","100 100 Loss: 2.591 | Acc: 33.920% (3392/10000)\n","Saving..\n","\n","Epoch: 5\n","1 391 Loss: 2.397 | Acc: 38.281% (49/128)\n","26 391 Loss: 2.424 | Acc: 37.470% (1247/3328)\n","51 391 Loss: 2.423 | Acc: 36.841% (2405/6528)\n","76 391 Loss: 2.437 | Acc: 36.462% (3547/9728)\n","101 391 Loss: 2.440 | Acc: 36.324% (4696/12928)\n","126 391 Loss: 2.444 | Acc: 35.993% (5805/16128)\n","151 391 Loss: 2.440 | Acc: 36.077% (6973/19328)\n","176 391 Loss: 2.441 | Acc: 36.048% (8121/22528)\n","201 391 Loss: 2.440 | Acc: 36.097% (9287/25728)\n","226 391 Loss: 2.442 | Acc: 36.069% (10434/28928)\n","251 391 Loss: 2.443 | Acc: 36.062% (11586/32128)\n","276 391 Loss: 2.441 | Acc: 36.161% (12775/35328)\n","301 391 Loss: 2.438 | Acc: 36.265% (13972/38528)\n","326 391 Loss: 2.436 | Acc: 36.263% (15132/41728)\n","351 391 Loss: 2.434 | Acc: 36.327% (16321/44928)\n","376 391 Loss: 2.430 | Acc: 36.334% (17487/48128)\n","391 391 Loss: 2.427 | Acc: 36.396% (18198/50000)\n","1 100 Loss: 2.437 | Acc: 41.000% (41/100)\n","26 100 Loss: 2.395 | Acc: 38.538% (1002/2600)\n","51 100 Loss: 2.415 | Acc: 37.373% (1906/5100)\n","76 100 Loss: 2.424 | Acc: 37.000% (2812/7600)\n","100 100 Loss: 2.424 | Acc: 37.060% (3706/10000)\n","Saving..\n","\n","Epoch: 6\n","1 391 Loss: 2.505 | Acc: 37.500% (48/128)\n","26 391 Loss: 2.342 | Acc: 38.311% (1275/3328)\n","51 391 Loss: 2.315 | Acc: 38.588% (2519/6528)\n","76 391 Loss: 2.290 | Acc: 38.857% (3780/9728)\n","101 391 Loss: 2.288 | Acc: 39.070% (5051/12928)\n","126 391 Loss: 2.271 | Acc: 39.534% (6376/16128)\n","151 391 Loss: 2.273 | Acc: 39.399% (7615/19328)\n","176 391 Loss: 2.278 | Acc: 39.289% (8851/22528)\n","201 391 Loss: 2.288 | Acc: 39.109% (10062/25728)\n","226 391 Loss: 2.289 | Acc: 39.059% (11299/28928)\n","251 391 Loss: 2.289 | Acc: 38.994% (12528/32128)\n","276 391 Loss: 2.280 | Acc: 39.077% (13805/35328)\n","301 391 Loss: 2.280 | Acc: 39.039% (15041/38528)\n","326 391 Loss: 2.280 | Acc: 39.156% (16339/41728)\n","351 391 Loss: 2.282 | Acc: 39.100% (17567/44928)\n","376 391 Loss: 2.281 | Acc: 39.127% (18831/48128)\n","391 391 Loss: 2.279 | Acc: 39.150% (19575/50000)\n","1 100 Loss: 2.520 | Acc: 41.000% (41/100)\n","26 100 Loss: 2.342 | Acc: 39.269% (1021/2600)\n","51 100 Loss: 2.343 | Acc: 39.157% (1997/5100)\n","76 100 Loss: 2.351 | Acc: 38.592% (2933/7600)\n","100 100 Loss: 2.350 | Acc: 38.730% (3873/10000)\n","Saving..\n","\n","Epoch: 7\n","1 391 Loss: 2.156 | Acc: 36.719% (47/128)\n","26 391 Loss: 2.117 | Acc: 42.728% (1422/3328)\n","51 391 Loss: 2.111 | Acc: 42.770% (2792/6528)\n","76 391 Loss: 2.117 | Acc: 42.681% (4152/9728)\n","101 391 Loss: 2.130 | Acc: 42.404% (5482/12928)\n","126 391 Loss: 2.134 | Acc: 42.299% (6822/16128)\n","151 391 Loss: 2.135 | Acc: 42.384% (8192/19328)\n","176 391 Loss: 2.143 | Acc: 42.298% (9529/22528)\n","201 391 Loss: 2.148 | Acc: 42.106% (10833/25728)\n","226 391 Loss: 2.148 | Acc: 42.184% (12203/28928)\n","251 391 Loss: 2.146 | Acc: 42.194% (13556/32128)\n","276 391 Loss: 2.148 | Acc: 42.100% (14873/35328)\n","301 391 Loss: 2.154 | Acc: 41.990% (16178/38528)\n","326 391 Loss: 2.158 | Acc: 41.833% (17456/41728)\n","351 391 Loss: 2.156 | Acc: 41.867% (18810/44928)\n","376 391 Loss: 2.156 | Acc: 41.938% (20184/48128)\n","391 391 Loss: 2.153 | Acc: 42.056% (21028/50000)\n","1 100 Loss: 2.335 | Acc: 44.000% (44/100)\n","26 100 Loss: 2.262 | Acc: 40.846% (1062/2600)\n","51 100 Loss: 2.276 | Acc: 40.882% (2085/5100)\n","76 100 Loss: 2.281 | Acc: 40.171% (3053/7600)\n","100 100 Loss: 2.273 | Acc: 40.380% (4038/10000)\n","Saving..\n","\n","Epoch: 8\n","1 391 Loss: 1.928 | Acc: 46.094% (59/128)\n","26 391 Loss: 2.019 | Acc: 45.613% (1518/3328)\n","51 391 Loss: 2.021 | Acc: 45.297% (2957/6528)\n","76 391 Loss: 2.024 | Acc: 45.210% (4398/9728)\n","101 391 Loss: 2.032 | Acc: 45.158% (5838/12928)\n","126 391 Loss: 2.026 | Acc: 45.176% (7286/16128)\n","151 391 Loss: 2.029 | Acc: 45.080% (8713/19328)\n","176 391 Loss: 2.040 | Acc: 44.780% (10088/22528)\n","201 391 Loss: 2.037 | Acc: 44.897% (11551/25728)\n","226 391 Loss: 2.035 | Acc: 44.915% (12993/28928)\n","251 391 Loss: 2.032 | Acc: 44.886% (14421/32128)\n","276 391 Loss: 2.035 | Acc: 44.928% (15872/35328)\n","301 391 Loss: 2.043 | Acc: 44.734% (17235/38528)\n","326 391 Loss: 2.041 | Acc: 44.800% (18694/41728)\n","351 391 Loss: 2.038 | Acc: 44.830% (20141/44928)\n","376 391 Loss: 2.042 | Acc: 44.770% (21547/48128)\n","391 391 Loss: 2.043 | Acc: 44.788% (22394/50000)\n","1 100 Loss: 2.177 | Acc: 45.000% (45/100)\n","26 100 Loss: 2.145 | Acc: 43.423% (1129/2600)\n","51 100 Loss: 2.154 | Acc: 43.333% (2210/5100)\n","76 100 Loss: 2.160 | Acc: 43.053% (3272/7600)\n","100 100 Loss: 2.153 | Acc: 43.070% (4307/10000)\n","Saving..\n","\n","Epoch: 9\n","1 391 Loss: 2.050 | Acc: 39.844% (51/128)\n","26 391 Loss: 1.893 | Acc: 47.716% (1588/3328)\n","51 391 Loss: 1.887 | Acc: 47.626% (3109/6528)\n","76 391 Loss: 1.905 | Acc: 47.338% (4605/9728)\n","101 391 Loss: 1.909 | Acc: 47.293% (6114/12928)\n","126 391 Loss: 1.914 | Acc: 47.247% (7620/16128)\n","151 391 Loss: 1.903 | Acc: 47.304% (9143/19328)\n","176 391 Loss: 1.912 | Acc: 47.128% (10617/22528)\n","201 391 Loss: 1.910 | Acc: 47.225% (12150/25728)\n","226 391 Loss: 1.922 | Acc: 47.013% (13600/28928)\n","251 391 Loss: 1.924 | Acc: 46.987% (15096/32128)\n","276 391 Loss: 1.923 | Acc: 46.994% (16602/35328)\n","301 391 Loss: 1.926 | Acc: 46.872% (18059/38528)\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-79b02014709a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'learning rate reduced to '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m       \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moverfit_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtest_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-79b02014709a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-79b02014709a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madaptive_avg_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-79b02014709a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m             new_features = F.dropout(new_features, p=self.drop_rate,\n\u001b[1;32m     51\u001b[0m                                      training=self.training)\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}